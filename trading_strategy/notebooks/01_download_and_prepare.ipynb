{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 01_download_and_prepare.ipynb\n",
    "# Descarga datos crudos, construye features y etiquetas,\n",
    "# y guarda datasets procesados por ticker.\n",
    "# ======================================\n",
    "\n",
    "from src.utils import load_config, ensure_dirs\n",
    "from src.data_loader import load_universe_data\n",
    "from src.features import build_features\n",
    "from src.labeler import make_labels\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "# --- 1. cargar config y asegurar estructura ---\n",
    "cfg = load_config()\n",
    "ensure_dirs()\n",
    "\n",
    "print(\"=== CONFIG ESTRATEGIA ===\")\n",
    "pprint.pprint(cfg[\"strategy\"])\n",
    "\n",
    "# --- 2. leer tickers ---\n",
    "with open(\"data/tickers.txt\") as f:\n",
    "    tickers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(\"=== TICKERS ===\")\n",
    "print(tickers)\n",
    "\n",
    "# --- 3. descargar datos crudos 1m ---\n",
    "raw_map = load_universe_data(\n",
    "    tickers,\n",
    "    cfg[\"data\"][\"lookback_days\"],\n",
    "    cfg[\"data\"][\"interval\"]\n",
    ")\n",
    "\n",
    "# --- 4. generar features y etiquetas por ticker ---\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "processed_info = []\n",
    "\n",
    "for t, df in raw_map.items():\n",
    "    print(f\"\\nProcesando {t}...\")\n",
    "\n",
    "    # features técnicos / contexto intradía\n",
    "    feat_df = build_features(df)\n",
    "\n",
    "    # etiquetas basadas en TP / SL / horizon\n",
    "    labeled_df = make_labels(\n",
    "        feat_df,\n",
    "        cfg[\"strategy\"][\"horizon\"],\n",
    "        cfg[\"strategy\"][\"tp\"],\n",
    "        cfg[\"strategy\"][\"sl\"]\n",
    "    )\n",
    "\n",
    "    # guardar dataset etiquetado para inspección offline\n",
    "    out_path = f\"data/processed/{t}_processed.csv\"\n",
    "    labeled_df.to_csv(out_path, index=True)\n",
    "    print(f\"✅ Guardado {out_path} ({len(labeled_df)} filas)\")\n",
    "\n",
    "    processed_info.append({\n",
    "        \"ticker\": t,\n",
    "        \"rows\": len(labeled_df),\n",
    "        \"path\": out_path\n",
    "    })\n",
    "\n",
    "print(\"\\n=== RESUMEN DATASETS GENERADOS ===\")\n",
    "for info in processed_info:\n",
    "    print(info)\n",
    "\n",
    "print(\"\\nListo. Ahora puedes revisar los CSV en data/processed/ o pasar al notebook 02_train_models.ipynb.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
